Be wary of potential AI deception during polls campaign, warns analyst
The risk of AI being used to spread false political propaganda must not be dismissed, says Harris Zainul.
PETALING JAYA: The authorities must seriously consider the potential for artificial intelligence (AI) to be abused to create “realistic” false materials during election campaigns, warns an analyst.

However, the Institute of Strategic and International Studies (Isis) senior analyst Harris Zainul admitted that such a sophisticated method of defamatory propaganda will not occur during the upcoming state elections but the possibility of it happening in the future should not be dismissed.
Speaking to FMT, he said the high cost and timeframe required to set up bot accounts capable of conducting false narrative campaigns is the current deterrent at this moment.
Harris said all parties must be aware of AI development and how it is being used.
This topic has triggered widespread dialogue among tech experts and politicians among global superpowers, including in the US. A US Senate hearing was held recently to discuss its risk during elections.
Researchers and observers in Malaysia have not found any concrete evidence that the community has been fed with AI-created propaganda but Harris reminds everyone to remain vigilant.

“That said, the dark horse will be AI-manipulated images, videos and audios.

“There is a saying that seeing is believing. In the chaotic information environment during election periods, voters may be swayed, based on this,” he said.

“My worry here is twofold. The first is that these technologies are being adopted quickly and quietly without the accompanying regulatory framework, transparency disclosures, and even punitive punishments for those spreading disinformation.
“At the same time, I am also equally worried that rushed legislative efforts could lead to unintended consequences such as increasing the risk of censorship and having a chilling effect on free speech.”

Balancing freedom and security

To address this threat, Harris said the government must take a careful approach and be detailed when amending or enacting new laws.

Lawmakers must find a balance between combating any form of disinformation – political or otherwise – while protecting freedom of speech.
Harris also dismissed the notion that bots will be replacing cybertroopers in the near future, due to the high price of developing the technology compared to hiring someone to manage fake accounts.

“My assessment is that bots will not replace human-operated accounts in the near future.
“The primary reason will be the cost of setting up bots that are able to run autonomously, and create and respond to political topics in a cohesive manner,” said Harris.

At the same time, the academic believes that large language model (LLM) technology such as ChatGPT will increase efficiency in creating political propaganda, which may or may not include misinformation and disinformation.